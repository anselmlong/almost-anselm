# ğŸ¤– Anselm AI â€” Telegram Persona LLM

A Telegram bot fine-tuned on my real conversation style, capable of chatting like me and continually improving via reinforcement feedback.

**Note: This README is generated with AI tools. Will be refined as the project goes along.**

---

## ğŸš€ Overview

Pipeline:
1. âœ… Pull Telegram messages (your side of conversations)
2. âœ… Clean + anonymize data
3. âœ… Build supervised training dataset (context â†’ your reply)
4. âœ… Fine-tune a 7B model with QLoRA
5. âœ… Add retrieval of similar past messages
6. âœ… Deploy as a Telegram bot that chats like you
7. âœ… RL preference tuning (â€œWould I reply like that?â€)

---

## ğŸ§± Tech Stack

| Component | Tool |
|---------|------|
| LLM Base | Mistral-7B-Instruct / Llama-3-8B-Instruct |
| Fine-tuning | Axolotl + QLoRA |
| Vector Store | FAISS |
| Telegram Integration | Telethon + python-telegram-bot |
| Inference | vLLM / Ollama |
| Preferences | DPO / KTO |

---

## ğŸ“¦ Setup & Installation

### 1ï¸âƒ£ Clone Repo
    git clone https://github.com/yourusername/telegram-anselm-ai.git
    cd telegram-anselm-ai

### 2ï¸âƒ£ Create Virtual Environment
    python -m venv venv
    source venv/bin/activate  # Mac/Linux
    venv\Scripts\activate     # Windows

### 3ï¸âƒ£ Install Requirements
    pip install -r requirements.txt

### 4ï¸âƒ£ Create Environment Variables
Copy `.env.example` â†’ `.env` and fill in:

    TG_API_ID=
    TG_API_HASH=
    BOT_TOKEN=
    HF_TOKEN=    # optional, if pulling private HF models

---

## ğŸ“¥ Data Collection

Pull your Telegram messages:

    cd src/data
    python pull_telegram.py

â¡ Output â†’ `data/raw/messages.json`

---

## ğŸ› Anonymize & Clean

    python anonymize.py

â¡ Output: `data/raw/messages_clean.json`

---

## ğŸ“ Dataset for SFT

    python build_dataset.py

â¡ Output: `data/processed/sft_data.json`

---

## ğŸ§ª Baseline Test (without training)

Try inference with base model + prompt examples to establish style baseline.

---

## ğŸ§  QLoRA Fine-Tuning

Ensure `axolotl_config.yaml` is configured correctly â†’ dataset & LoRA params

    cd src/train
    bash run_sft.sh

â¡ Outputs:
`models/adapters/` (LoRA adapters)

---

## ğŸ” Retrieval Augmentation

    cd src/inference
    python embed_store.py

Bot now retrieves semantically similar past messages â†’ more realistic style

---

## ğŸ¤– Telegram Bot Deployment

    cd src/bot
    python telegram_bot.py

Talk with your AI persona in Telegram ğŸ‰

---

## ğŸ¯ Evaluation

- Shuffle test (real vs. bot responses)
- Classifier: â€œAnselm vs. Generic AIâ€
- Track:
  - Latency
  - Hallucination rate
  - Conversation quality

---

## âš™ï¸ RL Preferences: DPO / KTO

Collect preference feedback:

    python ../rl/collect_prefs.py

Refine model:

    python ../rl/run_dpo.py

Republish updated persona â€” improves over time ğŸš€

---

## ğŸ” Privacy & Safety

âœ” Raw data stays local  
âœ” Other users are anonymized  
âœ” Add `/forget` to erase memory for any user  
âœ” Bot clearly states it is an AI version of Anselm

---

## âœ… Progress Tracker

See: **TODO.md**

---

## ğŸ™Œ Contributing

PRs welcome â€” especially around:
- anonymization,
- evaluation,
- safety tooling.

---

### â­ Give a star if you like this project!

--- 

## References

https://medium.com/data-science-collective/i-fine-tuned-an-llm-on-5-years-of-telegram-chats-7bacb66387c8
